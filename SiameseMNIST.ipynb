{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of SiameseMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOKepxMneaG7b/LiFh1ei1N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gdario/DL-workshop-2017/blob/master/SiameseMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyOv_C2jK7rq"
      },
      "source": [
        "In this notebook we create a siamese network to classify pairs of MNIST digits. The classifier must assess whether the two images represent the same digit or two different digits. For this purpose we build a `Dataset` that, for a given index `idx` will return with probability 0.5 a random image from the same class or an image from a different class. The model is just a MLP, and the purpose of this notebook is mainly to show how to build a non-standard `Dataset` and `DataLoader`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hf-bopjgnCWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a067e8d-6baa-4472-e977-2bfb511ffc5e"
      },
      "source": [
        "import gzip\n",
        "import pickle\n",
        "import random\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "torch.cuda.current_device()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "zSBy4EE0RPae",
        "outputId": "6e96e907-8f93-4d6a-9b53-8b6117963516"
      },
      "source": [
        "DATA_PATH = Path(\"data\")\n",
        "PATH = DATA_PATH / \"mnist\"\n",
        "PATH.mkdir(parents=True, exist_ok=True)\n",
        "URL = \"https://github.com/pytorch/tutorials/raw/master/_static/\"\n",
        "FILENAME = \"mnist.pkl.gz\"\n",
        "\n",
        "if not (PATH / FILENAME).exists():\n",
        "        content = requests.get(URL + FILENAME).content\n",
        "        (PATH / FILENAME).open(\"wb\").write(content)\n",
        "\n",
        "with gzip.open((PATH / FILENAME).as_posix(), \"rb\") as f:\n",
        "        ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(\n",
        "            f, encoding=\"latin-1\")\n",
        "\n",
        "pyplot.imshow(x_train[0].reshape((28, 28)), cmap=\"gray\")\n",
        "print(x_train.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DytRg0tv2TSL"
      },
      "source": [
        "The `y_train` and `y_valid` labels are not the ones we will use in our model. These are the original labels `[0, ..., 9]`, while we will be using a binary label that is equal to `1` when two images represent the same digit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFmXQ6C92sSc",
        "outputId": "a21ae3a5-5eca-4d3d-b43c-fb185f601e12"
      },
      "source": [
        "y_valid.dtype"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('int64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89SowtwDZ_p_",
        "outputId": "ef6d8b07-171d-40c7-a77a-d524199b23df"
      },
      "source": [
        "x_train, x_valid = torch.tensor(x_train), torch.tensor(x_valid)\n",
        "# y_train, y_valid = torch.tensor(y_train), torch.tensor(y_valid)\n",
        "x_train.dtype, x_valid.dtype, y_train.dtype, y_valid.dtype"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.float32, torch.float32, dtype('int64'), dtype('int64'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-7uh8iUbbXO",
        "outputId": "7dbafa7f-659d-4091-a18c-a890793646c3"
      },
      "source": [
        "y_valid[5].shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH7aklbZ1xWA"
      },
      "source": [
        "We want to create a dataloader that returns, with the same probability, two different images of the same number, or two images of two different numbers. There are 10 classes, therefore the probability of each class is 1/10. The probability of getting the same number twice is therefore 1/00 = 0.01. There are 10 classes, therefore the probability of getting the same class twice is 10%. We generate pairs of class labels c1 and c2 and with probability 60% we set c2 to the same value of c1. The cutoff is 60% because 10% of the cases will contain the same class anyway."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fCtPh-KGluX"
      },
      "source": [
        "class MNISTpairSet(Dataset):\n",
        "    def __init__(self, x_data, y_data):\n",
        "        super().__init__()\n",
        "        self.x = x_data\n",
        "        self.y = y_data\n",
        "        self.classes = torch.tensor([[0], [1]], dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.y.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x1 = self.x[idx]\n",
        "        y1 = self.y[idx]\n",
        "        y2 = random.randint(0, 9)\n",
        "        if random.random() > 0.6:\n",
        "            y2 = y1\n",
        "        tmp = self.x[self.y == y2]\n",
        "        # idx2 = torch.randint(low=0, high=tmp.shape[0], size=(1,)).item()\n",
        "        idx2 = random.randint(0, tmp.shape[0] - 1)\n",
        "        x2 = tmp[idx2]\n",
        "        y = self.classes[1] if y1 == y2 else self.classes[0]\n",
        "        # sample = {'x1': x1, 'x2': x2, 'y': y}\n",
        "        return (x1, x2, y)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICZIJrDeMCMD"
      },
      "source": [
        "The model below contains two layers the weights of which are shared betwee the two branches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBips6quiHyy"
      },
      "source": [
        "dataset_train = MNISTpairSet(x_train, y_train)\n",
        "dataset_valid = MNISTpairSet(x_valid, y_valid)\n",
        "\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=64, shuffle=False)\n",
        "dataloader_valid = DataLoader(dataset_valid, batch_size=64, shuffle=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owQQGuJQ4Fui"
      },
      "source": [
        "class SiameseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.shared_linear1 = nn.Linear(in_features=784, out_features=256)\n",
        "        self.shared_linear2 = nn.Linear(in_features=256, out_features=128)\n",
        "        self.linear1 = nn.Linear(in_features=256, out_features=128)\n",
        "        self.linear2 = nn.Linear(in_features=128, out_features=1)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = F.relu(self.shared_linear1(x1))\n",
        "        x2 = F.relu(self.shared_linear1(x2))\n",
        "        x1 = F.relu(self.shared_linear2(x1))\n",
        "        x2 = F.relu(self.shared_linear2(x2))\n",
        "        x = torch.cat((x1, x2), dim=1)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NXc7BQ_beih"
      },
      "source": [
        "def training_loop(train_loader, valid_loader, device, model, loss_fn,\n",
        "                  optimizer):\n",
        "    losses = []\n",
        "    batch_num = 0\n",
        "    for x1, x2, y in train_loader:\n",
        "        batch_num += 1\n",
        "        x1 = x1.to(device)\n",
        "        x2 = x2.to(device)\n",
        "        y = y.to(device)\n",
        "        preds = model(x1, x2)\n",
        "        loss = loss_fn(preds, y)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "        if batch_num % 200 == 0:\n",
        "            print('Batch: {}, Train loss: {:.4f}'.format(\n",
        "                batch_num+1, loss.item()))\n",
        "            validation_loop(valid_loader, device, model, loss_fn)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RF_rAhPiGxx"
      },
      "source": [
        "def validation_loop(dataloader, device, model, loss_fn):\n",
        "    size = len(dataloader)  # Number of minibatches, not of observations\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for x1, x2, y in dataloader:\n",
        "            x1 = x1.to(device)\n",
        "            x2 = x2.to(device)\n",
        "            y = y.to(device)\n",
        "            preds = model(x1, x2)\n",
        "            test_loss += loss_fn(preds, y)\n",
        "            yhat = (torch.sigmoid(preds) > 0.5).type(torch.float)\n",
        "            correct += (yhat == y).type(torch.float).mean().item()\n",
        "        test_loss /= size\n",
        "        correct /= size\n",
        "        print(f'Test Loss: {test_loss:>.4} - Test Accuracy {correct:>0.3f}')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpTHEZ9LHVHW",
        "outputId": "64d59257-4638-4b82-e149-a5d99a5e1e50"
      },
      "source": [
        "NUM_EPOCHS = 5\n",
        "\n",
        "model = SiameseNet()\n",
        "model = model.to(device)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999))\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print('Epoch: {}'.format(epoch))\n",
        "    print('-----------------------')\n",
        "    training_loop(dataloader_train, dataloader_valid, device, model,\n",
        "                  loss_fn, optimizer)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "-----------------------\n",
            "Batch: 201, Train loss: 0.4306\n",
            "Test Loss: 0.4465 - Test Accuracy 0.782\n",
            "Batch: 401, Train loss: 0.3244\n",
            "Test Loss: 0.3412 - Test Accuracy 0.856\n",
            "Batch: 601, Train loss: 0.2609\n",
            "Test Loss: 0.2652 - Test Accuracy 0.896\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}